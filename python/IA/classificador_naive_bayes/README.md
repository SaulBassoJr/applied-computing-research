# Classificador Naive Bayes com SeleÃ§Ã£o de Atributos usando Hill Climbing

Este script aplica o classificador **Naive Bayes** sobre o conjunto de dados "Congressional Voting Records" do repositÃ³rio UCI, realizando uma **seleÃ§Ã£o de atributos** com o mÃ©todo de busca **Hill Climbing**.

## ğŸ“š ConteÃºdos abordados

- Carregamento de dados com `ucimlrepo`
- PrÃ©-processamento de dados (conversÃ£o de valores categÃ³ricos e imputaÃ§Ã£o)
- Treinamento e avaliaÃ§Ã£o de um classificador Naive Bayes
- SeleÃ§Ã£o de atributos com Hill Climbing

## ğŸ“Š Sobre o classificador Naive Bayes (NB)

Ã‰ um dos algoritmos de aprendizado supervisionado mais simples e amplamente utilizados, baseado no Teorema de Bayes com a suposiÃ§Ã£o de independÃªncia condicional entre as caracterÃ­sticas.

### Teorema de Bayes

O Teorema de Bayes Ã© a base matemÃ¡tica por trÃ¡s do classificador Naive Bayes. Ele descreve a probabilidade de um evento A ocorrer, dado que o evento B ocorreu, usando as probabilidades condicionais. A fÃ³rmula Ã©:

â€‹Onde:

- P(A|B) Ã© a probabilidade de A dado B.
- P(B|A) Ã© a probabilidade de B dado A.
- P(A) Ã© a probabilidade a priori de A.
- P(B) Ã© a probabilidade a priori de B.

No contexto do Naive Bayes, estamos interessados em calcular a probabilidade de uma classe ğ¶ dada as caracterÃ­sticas ğ‘‹1,ğ‘‹2,...,ğ‘‹ğ‘› (onde ğ‘‹i sÃ£o os atributos ou caracterÃ­sticas de entrada), ou seja, ğ‘ƒ(ğ¶âˆ£ğ‘‹1,ğ‘‹2,...,ğ‘‹ğ‘›)

### Tipos de Classificadores Naive Bayes

Existem diferentes variaÃ§Ãµes do Naive Bayes, dependendo da natureza dos dados de entrada. Os mais comuns sÃ£o:

1. Gaussian Naive Bayes (GaussianNB):

   - Usado quando as caracterÃ­sticas (atributos) sÃ£o contÃ­nuas e seguem uma distribuiÃ§Ã£o normal (gaussiana).
   - Para cada classe, Ã© estimada a mÃ©dia e a variÃ¢ncia das caracterÃ­sticas, e essas informaÃ§Ãµes sÃ£o usadas para calcular a probabilidade de cada caracterÃ­stica dada a classe.

2. Multinomial Naive Bayes (MultinomialNB):

   - Usado quando as caracterÃ­sticas representam contagens de eventos discretos (por exemplo, frequÃªncia de palavras em texto).
   - Ã‰ muito utilizado em problemas de classificaÃ§Ã£o de texto (como spam vs nÃ£o spam).

3. Bernoulli Naive Bayes (BernoulliNB):
   - Usado quando as caracterÃ­sticas sÃ£o binÃ¡rias (ex: presenÃ§a ou ausÃªncia de uma palavra em um texto, 1 ou 0).
   - Similar ao MultinomialNB, mas assume que cada caracterÃ­stica Ã© uma variÃ¡vel binÃ¡ria.

### Como o Naive Bayes Funciona na PrÃ¡tica

1. Treinamento (Fase de Ajuste):

   - O modelo Ã© treinado com um conjunto de dados rotulados (com as classes jÃ¡ conhecidas).
   - Durante o treinamento, para cada classe, o modelo calcula:
     - A probabilidade a priori da classe ğ‘ƒ(ğ¶).
     - A probabilidade condicional de cada caracterÃ­stica dado a classe ğ‘ƒ(ğ‘‹ğ‘–âˆ£ğ¶).
   - As probabilidades ğ‘ƒ(ğ¶) e ğ‘ƒ(ğ‘‹ğ‘–âˆ£ğ¶) podem ser calculadas a partir das frequÃªncias observadas nos dados de treinamento.

2. PrediÃ§Ã£o (Fase de InferÃªncia):
   - Quando o modelo Ã© aplicado a dados de teste, ele calcula as probabilidades ğ‘ƒ(ğ¶âˆ£ğ‘‹1,ğ‘‹2,...,ğ‘‹ğ‘›) para cada classe possÃ­vel ğ¶, e escolhe a classe com a maior probabilidade.
   - A previsÃ£o Ã© dada pela classe ğ¶ que maximiza a expressÃ£o de Bayes.

## ğŸ“Š Sobre o Dataset

O dataset contÃ©m os registros de votaÃ§Ã£o de 435 membros da CÃ¢mara dos Representantes dos EUA em 1984. Cada amostra indica o voto de um congressista em 16 propostas legislativas, com os seguintes valores:

- `y` â†’ Votou sim (convertido para 1)
- `n` â†’ Votou nÃ£o (convertido para 0)
- `?` â†’ Ausente ou voto desconhecido (convertido para `NaN`, tratado com imputaÃ§Ã£o)

As classes sÃ£o:

- **republican**
- **democrat**

O dataset Ã© carregado diretamente da biblioteca `ucimlrepo`.

## ğŸ” Como rodar

### Requisitos

VocÃª precisa ter instalado:

- Python 3.8+
- `scikit-learn`
- `pandas`
- `ucimlrepo`

Instale com:

```bash
pip install scikit-learn
```

```bash
pip install pandas
```

```bash
pip install ucimlrepo
```

## ğŸ“„ Sobre o CÃ³digo

Este projeto implementa um classificador Naive Bayes para prever a filiaÃ§Ã£o partidÃ¡ria de membros do congresso com base em seus votos em diferentes projetos de lei. A seleÃ§Ã£o de atributos Ã© feita utilizando o algoritmo Hill Climbing, que busca maximizar a acurÃ¡cia da classificaÃ§Ã£o.

### ğŸ” ExplicaÃ§Ã£o do Funcionamento

1. Carregamento do dataset

- Usa `fetch_ucirepo(id=105)` para obter os dados do Congressional Voting Records.

2. PrÃ©-processamento

   - Os valores 'y', 'n' e '?' sÃ£o convertidos para 1, 0 e `NaN`, respectivamente.
   - Os valores ausentes sÃ£o substituÃ­dos pela moda (valor mais frequente) da coluna.

3. DivisÃ£o treino/teste

   - Os dados sÃ£o divididos aleatoriamente em 70% para treino e 30% para teste.

4. Treinamento do Naive Bayes

   - Utiliza `GaussianNB` da biblioteca `scikit-learn`.

5. Hill Climbing para seleÃ§Ã£o de atributos
   - ComeÃ§a com nenhum atributo selecionado
   - A cada iteraÃ§Ã£o, adiciona o atributo que mais aumenta a acurÃ¡cia
   - Para quando nÃ£o hÃ¡ mais melhorias

### â–¶ï¸ Ordem de ExecuÃ§Ã£o

```bash
â¬‡ï¸ ImportaÃ§Ãµes
â¬‡ï¸ Carrega e prepara os dados
â¬‡ï¸ Converte valores categÃ³ricos e trata os ausentes
â¬‡ï¸ Divide treino e teste
â¬‡ï¸ Executa Hill Climbing (treina e testa modelos com diferentes atributos)
â¬‡ï¸ Imprime os resultados
```

### ğŸ FunÃ§Ãµes em Python utilizadas

- `replace()`: Substitui valores categÃ³ricos por numÃ©ricos.
- `SimpleImputer`: Substitui valores ausentes pela moda.
- `train_test_split()`: Divide os dados em treino e teste.
- `GaussianNB()`: Implementa o classificador Naive Bayes.
- `accuracy_score()`: Mede a acurÃ¡cia da classificaÃ§Ã£o.
- `list comprehension`: Usada para selecionar subconjuntos de atributos.

### ğŸ§® Exemplo de SaÃ­da

```bash
Atributos Selecionados: [3]
Melhor AcurÃ¡cia: 0.9694656488549618
```

## ğŸ“š PossÃ­veis ExpansÃµes

Usar outros classificadores: Decision Tree, KNN, SVM

Avaliar com mÃ©tricas adicionais: F1-score, matriz de confusÃ£o

Comparar diferentes tÃ©cnicas de seleÃ§Ã£o de atributos: RFE, Random Search

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido por [Saul Basso Junior]
